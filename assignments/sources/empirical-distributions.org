#+title: Queueing theory Assignment: Empirical distributions.
#+author: Nicky D. van Foreest
#+date: 2022:01:19

#+STARTUP: indent
#+STARTUP: overview
#+PROPERTY: header-args :session  :exports both   :dir "./figures/" :results output

#+include: preamble.org


* TODO Set theme and font size for youtube                         :noexport:

#+begin_src emacs-lisp :eval no-export
(modus-themes-load-operandi)
(set-face-attribute 'default nil :height 200)
#+end_src

#+RESULTS:

* Empirical distribution, how to make and plot

We want to know the fraction of periods the queue length is longer than some value $q$, say. For this we will make the empirical distribution of the queue lengths.

** Plotting a PDF/histogram

#+begin_src python :results value file
import matplotlib.pyplot as plt

x = [2, 5, 2, 1, 9, 5, 5, 5]

plt.clf()
plt.hist(x, bins=3, facecolor='red', edgecolor='black', linewidth=1)
plt.savefig('emp0.pdf')
#+end_src

#+begin_src python :results value file :exports results
'emp0.pdf'
#+end_src

#+RESULTS:
[[file:figures/emp0.pdf]]


#+begin_exercise
What happens if  you set ~bins=10~ and then run the simulation? Include a graph to show this.
#+end_exercise

** First naive idea

Given a set of measurements $x_{1}, \ldots, x_n$, the empirical CDF is defined as
\begin{align*}
F(x) = \frac{1}{n}\sum_{i=1}^n \1{x_i \leq x}
\end{align*}
This is a clean mathematical definition, but as if often the case with mathematical definitions, you should stay clear from using it to /compute/ the CDF: the numerical performance is absolutely terrible.


#+begin_src python
x = [2, 5, 2, 1, 8, 5, 5]

def F(y):
    tot = 0
    for xi in x:
        tot += xi <= y # this

    return  tot/len(x)

print(F(5.5))
#+end_src

#+RESULTS:
: 0.875

#+begin_exercise
Explain first how the ~this~ line works.
#+begin_hint
Run this code to see what happens
#+begin_src python
print(3 < 4)
jj = 0
jj += 3 < 4
print(jj)
#+end_src
#+end_hint
#+end_exercise

#+begin_exercise
Explain in your own words why this way to compute the empirical CDF is a not so smart (i.e., pretty dumb) idea.
#+begin_hint
How many comparisons are required for each value of $F(y)$?
#+end_exercise

** A better idea

#+begin_src python
print(sorted(x))
#+end_src

#+RESULTS:
: [1, 2, 5, 8]


#+begin_src python
plt.clf()
plt.plot(sorted(x))
plt.savefig("emp00.pdf")
#+end_src

#+begin_src python :results value file :exports results
"emp00.pdf"
#+end_src

#+RESULTS:
[[file:figures/emp00.pdf]]



** Yet better idea

#+begin_src python
def cdf_better(x):
    x = sorted(x)
    n = len(x)
    y = range(1, n + 1)
    y = [z / n for z in y]  # normalize
    return x, y


x = [2, 5, 2, 1, 8, 5, 5]
x, F = cdf_better(x)
print(F)
#+end_src

#+RESULTS:
| 0.14285714285714285 | 0.2857142857142857 | 0.42857142857142855 | 0.5714285714285714 | 0.7142857142857143 | 0.8571428571428571 | 1.0 |

#+begin_exercise
Why do we divide by $n$ to normalize?
#+end_exercise

You should know that ~for~ loops in R and python are quite slow. We use this in the list comprehension in the line in which we ~#normalize~.
For larger amounts of data it is better to use =numpy=. This we do below.


** Plot the cdf

#+begin_src python
x = [2, 5, 2, 1, 8, 5, 5, 5]
x, F = cdf_better(x)
#+end_src


#+begin_src python
plt.clf()
plt.step(x, F)
plt.savefig("emp2.pdf")
#+end_src

#+RESULTS:

#+begin_src python :results value file :exports results
"emp2.pdf"
#+end_src

#+RESULTS:
[[file:figures/emp2.pdf]]


#+begin_src python
plt.clf()
plt.plot(x, F, drawstyle="steps-post")
plt.savefig("emp3.pdf")
#+end_src

#+RESULTS:

#+begin_src python :results value file :exports results
"emp3.pdf"
#+end_src

#+RESULTS:
[[file:figures/emp3.pdf]]

#+begin_exercise
Explain the differences between these different graphs. Which is the correct one? (Read the code well to see what happens.)
#+end_exercise


** Faster with numpy

#+begin_src python
import numpy as np

def cdf(x):
    y = np.arange(1, len(x) + 1) / len(x)
    x = np.sort(x)
    return x, y

x = [2, 5, 2, 1, 8, 5, 5]
x, F = cdf(x)
print(F)
#+end_src

#+RESULTS:
| 0.14285714 | 0.28571429 | 0.42857143 | 0.57142857 | 0.71428571 | 0.85714286 | 1 |

** Remove duplicate values

Finally, we can make the computation of the cdf significantly faster with using the following numpy functions.

#+begin_src python
unique, count = np.unique(np.sort(x), return_counts=True)
print(unique, count)
#+end_src

#+RESULTS:
| array | ((1 2 5 8)) | array | ((1 2 3 1)) |

#+begin_exercise
Explain what ~np.unique~ does and how this improves the speed of the computation of the ECDF (empirical CDF). What happens if you forget to sort the input ~x~?
#+end_exercise


#+begin_src python
print(count.cumsum()/7)
#+end_src

#+RESULTS:
| 0.14285714 | 0.42857143 | 0.85714286 | 1 |

#+begin_exercise
What is ~cumsum~?
#+end_exercise

#+begin_src python
def cdf_fastest(x):
    # remove multiple occurences of the same value
    unique, count = np.unique(x, return_counts=True)
    x = unique
    y = count.cumsum() / count.sum()
    return x, y

x = [2, 5, 2, 1, 8, 5, 5]
x, F = cdf_fastest(x)
print(F)
#+end_src

#+RESULTS:
| 0.14285714 | 0.42857143 | 0.85714286 | 1 |

#+begin_exercise
Find the CDF for arrival times [2,5,7,8,9,10] and plot it.
#+end_exercise


#+begin_exercise
Explain what  the Kolmogorov-Smirnov test has to do with the ECDF; search on the web for this. Keep your discussion short, but to the point.
#+end_exercise




* Waiting times and sums of RVS

Suppose that $X_k$ is uniformly distributed on the set $\{1,2,4\}$ and $S_k$ uniform on the set $\{1,2,3\}$.\sidenote{Hence, $\rho<1$.}
Starting with $W_{0}=5$, we like to construct the \emph{distribution} of the waiting times with the rule $W_{k}=[W_{k-1}+S_{k-1}-X_k]^+$.

Observe that this rule contains three steps.
First, we compute a new random variable $Z_k = W_{k-1} + S_{k-1}$, then  $Z_k' = Z_k - X_k$, and finally $[Z_k']^+$.
In other words, we first compute the sum of two independent random variables, then the difference, and finally apply a function $[.]^+$.

Now, when $X$ and $Y$ are independent with densities $f_X$ and $f_Y$, then it is well-known that
\begin{align*}
f_{X\pm Y}(n) &= \sum_i \sum_j f_X(i) f_Y(j)\1{i\pm j = n}, & f_{h(X)}(n) &= \sum_{i} f_X(i)\1{h(i)=n}.
\end{align*}
We implement these rules in the code below, but slightly more efficiently.\sidenote{We advice the reader to study this code well; there is much to learn.}
For instance, the computation of the distribution of $X+Y$, $X-Y$, and so on, have much in common.
We therefore build one method \pyv{apply_operator} that applies an operator like $+$ or $-$ to two independent random variables.
Then we use this code to compute the sum in line 24, and the difference in line 27.


\begin{pyblock}[waiting_exact][numbers=left,frame=lines]
from collections import defaultdict
import operator

class RV(defaultdict):
    def __init__(self, p=None):
        super().__init__(float)
        if p:
            for (i, pi,) in p.items():
                self[i] = pi

    def apply_operator(self, Y, op):
        R = RV()
        for (i, pi,) in self.items():
            for (j, pj,) in Y.items():
                R[op(i, j)] += pi * pj
        return R

    def apply_function(self, h):
        R = RV()
        for (i, pi,) in self.items():
            R[h(i)] += pi
        return R

    def __add__(self, X):
        return self.apply_operator(X, operator.add)

    def __sub__(self, X):
        return self.apply_operator(X, operator.sub)

    def plus(self):
        return self.apply_function(lambda x: max(x, 0))

    def support(self):
        return sorted(self.keys())

    def pmf(self):
        return [self[k] for k in self.support()]

\end{pyblock}


\newthought{We are now} ready to compute and plot the pmf of $W_k$ for increasing values of $k$.

\begin{pyblock}[waiting_exact][numbers=left,frame=lines]
from matplotlib.pylab import plt
import tikzplotlib
from matplotlib import style
style.use('ggplot')

W = RV({5: 1})
X = RV({1: 1 / 3, 2: 1 / 3, 4: 1 / 3,})
S = RV({1: 1 / 3, 2: 1 / 3, 3: 1 / 3,})

for n in range(1, 21):
    W += S - X
    W = W.plus()
    if n % 5 == 0:
        plt.plot(W.support(), W.pmf(), label="k={}".format(n))

\end{pyblock}

\begin{marginfigure}
\begin{pycode}[waiting_exact]
plt.axis([0, 20, 0, 0.3])
plt.legend()
print(tikzplotlib.get_tikz_code(axis_height="5cm", axis_width="6cm"))
\end{pycode}
\caption{The pmf of $W_k$.}
\label{fig:w_k}
\end{marginfigure}

With the code above we make~\cref{fig:w_k}.


As an aside for the python aficionados, the code can be made yet a bit cleaner with defining  \pyv{plus = operator.methodcaller("plus")} so that we can write
\pyv{W = plus(W + S - X)}.


Let us provide some intuition for this phenomenon by means of an example.

Suppose that $X_k$ is uniformly distributed on the set $\{1,2,4\}$ and $S_k$ uniform on the set $\{1,2,3\}$.\sidenote{Hence, $\rho<1$.}
Starting with $W_{0}=5$, we  construct the \emph{distribution} of the waiting times $W_1, W_{2}, \ldots$ with the rule $W_{k}=[W_{k-1}+S_{k-1}-X_k]^+$.\sidenote{Convince yourself why this requires quite a bit of numerical work.}
In ~\cref{fig:w_k} we see that,, for $k=5$, the pmf still contains a `hump' just below $x=5$, which is due the starting value of $W_{0}=5$.
\begin{marginfigure}
\begin{pycode}[waiting_exact]
from collections import defaultdict
import operator

class RV(defaultdict):
    def __init__(self, p=None):
        super().__init__(float)
        if p:
            for (i, pi,) in p.items():
                self[i] = pi

    def apply_operator(self, Y, op):
        R = RV()
        for (i, pi,) in self.items():
            for (j, pj,) in Y.items():
                R[op(i, j)] += pi * pj
        return R

    def apply_function(self, h):
        R = RV()
        for (i, pi,) in self.items():
            R[h(i)] += pi
        return R

    def __add__(self, X):
        return self.apply_operator(X, operator.add)

    def __sub__(self, X):
        return self.apply_operator(X, operator.sub)

    def plus(self):
        return self.apply_function(lambda x: max(x, 0))

    def support(self):
        return sorted(self.keys())

    def pmf(self):
        return [self[k] for k in self.support()]



from matplotlib.pylab import plt
import tikzplotlib
from matplotlib import style
style.use('ggplot')

W = RV({5: 1})
X = RV({1: 1 / 3, 2: 1 / 3, 4: 1 / 3,})
S = RV({1: 1 / 3, 2: 1 / 3, 3: 1 / 3,})

for n in range(1, 21):
    W += S - X
    W = W.plus()
    if n % 5 == 0:
        plt.plot(W.support(), W.pmf(), label="k={}".format(n))



plt.axis([0, 20, 0, 0.3])
plt.legend()
print(tikzplotlib.get_tikz_code(axis_height="5cm", axis_width="6cm"))
\end{pycode}
\caption{The pmf of $W_k$.}
\label{fig:w_k}
\end{marginfigure}
However, for $k\geq 10$, the pmf hardly changes.
The sequence of pmfs appears  to converge rather fast as $k$ increases.




* Restore my emacs settings   :noexport:

#+begin_src emacs-lisp :eval no-export
(modus-themes-load-vivendi)
(set-face-attribute 'default nil :height 100)
#+end_src

#+RESULTS:
