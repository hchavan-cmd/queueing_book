#+title: Queueing Theory and Simulation, lecture 8
#+author: Nicky van Foreest
#+date: \today
#+email: n.d.van.foreest@rug.nl

#+options: H:2 email:t num:t tex:t toc:t LaTeX:t
#+language: en
#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [bigger]
# +beamer_theme: Copenhagen
#+beamer_theme: metropolis

#+include: preamble.org


* Overview
** Past
- Finish  approximations, $G/G/1$  queue in tandem
- Start with exact work: renewal reward theorem
- application to queueing: fraction of time the servers are busy is $\lambda \E S$.
** Now
Very elegant use of sample paths (ideas based on simuation) to obtain crucial work horses of queueing theory:
- Level crossing
- PASTA
** Future
- Little's law
- All is set in place to analyze exact queueing models
* Level crossing argument
** Notation and concepts

\begin{align}
\label{eq:1}
 A(n,t) &= \sum_{k=1}^\infty \1{A_k \leq t}\1{\L(A_k-) = n} = \sum_{k=1}^{A(t)}\1{\L(A_k-) = n} \\
 Y(n,t) &= \int_0^t \1{\L(s) = n} \d s, \\
 p(n, t) &= \frac{Y(n,t)}t,\\
D(n,t) &= \sum_{k=1}^\infty \1{D_k \leq t} \1{\L(D_k) = n} = \sum_{k=1}^{D(t)} \1{\L(D_k) = n}
\end{align}
** Useful limits
\begin{align}
\label{eq:1}
\lambda(n) &= \lim_{t\to\infty} \frac{A(n,t)}{Y(n,t)} \\
p(n) &=\lim_{t\to\infty} p(n,t) \\
\mu(n+1) &= \lim_{t\to\infty} \frac{D(n,t)}{Y(n+1,t)}.
\end{align}

** Level crossing
\begin{align}
1 &\geq |A(n,t) - D(n,t)|, \\
 \lim_{t\to\infty} \frac{A(n,t)}t &= \lim_{t\to\infty} \frac{D(n,t)}t,\\
\lim_{t\to\infty} \frac{A(n,t)}t &= \lim_{t\to\infty} \frac{A(n,t)}{Y(n,t)}\frac{Y(n,t)}t = \lambda(n) p(n), \\
\lim_{t\to\infty} \frac{D(n,t)}t &= \lim_{t\to\infty} \frac{D(n,t)}{Y(n+1,t)}\frac{Y(n+1,t)}t \\
&= \mu(n+1) p(n+1), \\
&\implies \\
 \lambda(n) p(n) &= \mu(n+1)p(n+1).
\end{align}
We have a recursion!
** Specific queueing systems
By making proper choices for $\lambda(n)$ and $\mu(n)$ we can model many different queueing systems
- $M/M/1$: $\lambda(n) = \lambda, \mu(n) =\mu$.
- $M/M/\infty$: $\lambda(n) = \lambda, \mu(n) =  \mu n$.
- $M/M/c$: $\lambda(n) = \lambda, \mu(n) = \mu \min\{n, c\}$.
- $M/M/c/c$: $\lambda(n) = \lambda \1{n< c}, \mu(n) = \mu n.

** Implications
\begin{align}
 p(n+1) &= \frac{\lambda(n)}{\mu(n+1)}p(n),\\
 p(n+1) &= \frac{\lambda(n)\lambda(n-1)\cdots \lambda(0)}{\mu(n+1)\mu(n)\cdots \mu(1)}p(0) \\
1 &= p(0) \left(1+\sum_{n=0}^\infty \frac{\lambda(n)\lambda(n-1)\cdots\lambda(0)}{\mu(n+1)\mu(n)\cdots \mu(1)} \right)\\
\end{align}

** KPIs
\begin{align}
\E\L &= \sum_{n=0}^\infty n p(n), \\
\P{\L \geq n} &= \sum_{i=n}^\infty p(i).
\end{align}

* PASTA
** Notation and concepts
\begin{align}
\label{eq:3}
\frac{A(n,t)}t &= \frac{A(n,t)}{Y(n,t)}\frac{Y(n,t)}t \to \lambda(n) p(n), \quad\text{as } t \to \infty, \\
 \frac{A(n,t)}{t} &= \frac{A(t)}t \frac{A(n,t)}{A(t)}, \\
\frac{A(n,t)}{A(t)} &= \frac1{A(t)}\sum_{k=1}^{A(t)} \1{\L(A_k-) = n}, \\
\pi(n) &= \lim_{t\to\infty}\frac1{A(t)}\sum_{k=1}^{A(t)} \1{\L(A_k-) = n}, \\
&\implies \\
\lambda(n) p(n) &= \lambda \pi(n)
\end{align}

** PASTA (Poisson arrivals see time averages)
- $\lambda(n) = \lambda \iff p(n) = \pi(n)$.
- Jobs arrive as a Poisson process $\implies \lambda(n) = \lambda$. (Hard to prove)
$\implies$
- Jobs arrive as a Poisson process $\implies p(n) = \pi(n)$

In other words, when you sample a system at times $\{T_{k}\}$ such that $T_{k}-T_{k-1}$ are exp.
distributed, then sample averages converge to the time averages!
